{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>speed</th>\n",
       "      <th>strength</th>\n",
       "      <th>dexterity</th>\n",
       "      <th>constitution</th>\n",
       "      <th>intelligence</th>\n",
       "      <th>wisdom</th>\n",
       "      <th>charisma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dragonborn</td>\n",
       "      <td>79</td>\n",
       "      <td>279</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dragonborn</td>\n",
       "      <td>79</td>\n",
       "      <td>331</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dragonborn</td>\n",
       "      <td>71</td>\n",
       "      <td>230</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dragonborn</td>\n",
       "      <td>75</td>\n",
       "      <td>265</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dragonborn</td>\n",
       "      <td>72</td>\n",
       "      <td>229</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>tiefling</td>\n",
       "      <td>63</td>\n",
       "      <td>146</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>tiefling</td>\n",
       "      <td>72</td>\n",
       "      <td>230</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>tiefling</td>\n",
       "      <td>66</td>\n",
       "      <td>137</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>tiefling</td>\n",
       "      <td>68</td>\n",
       "      <td>143</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>tiefling</td>\n",
       "      <td>70</td>\n",
       "      <td>201</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            race  height  weight  speed  strength  dexterity  constitution  \\\n",
       "0     dragonborn      79     279     30        14         15            12   \n",
       "1     dragonborn      79     331     30        11         11            11   \n",
       "2     dragonborn      71     230     30        14         16            11   \n",
       "3     dragonborn      75     265     30         8         19             7   \n",
       "4     dragonborn      72     229     30         8         17            14   \n",
       "...          ...     ...     ...    ...       ...        ...           ...   \n",
       "9995    tiefling      63     146     30        13         18            17   \n",
       "9996    tiefling      72     230     30         8         14            13   \n",
       "9997    tiefling      66     137     30         4          5            16   \n",
       "9998    tiefling      68     143     30        12         16            12   \n",
       "9999    tiefling      70     201     30        16         17            15   \n",
       "\n",
       "      intelligence  wisdom  charisma  \n",
       "0                7      13        16  \n",
       "1               13      13        17  \n",
       "2               13      10        18  \n",
       "3               10      13        16  \n",
       "4               14      10         9  \n",
       "...            ...     ...       ...  \n",
       "9995            13      15        13  \n",
       "9996             6      14        20  \n",
       "9997            12      12        15  \n",
       "9998            15       9        16  \n",
       "9999            12      13        13  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"stats.csv\")\n",
    "\n",
    "df\n",
    "pd.set_option('display.max_rows', 60)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    " \n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df.copy()\n",
    "\n",
    "for i in  range(df.shape[1]-1):\n",
    "    df_2[df_2.columns[i+1]]=df[df.columns[i+1]]**3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df_2['race'] = label_encoder.fit_transform(df['race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"race\",axis=1)\n",
    "y = df[\"race\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32, input_dim = X_train.shape[1] ,activation = \"relu\"),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(df['race'].unique()), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['race'] = label_encoder.fit_transform(df['race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"race\",axis=1)\n",
    "y = df[\"race\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "125/125 [==============================] - 1s 3ms/step - loss: 1.5683 - accuracy: 0.3246 - val_loss: 1.3570 - val_accuracy: 0.4055\n",
      "Epoch 2/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1950 - accuracy: 0.4793 - val_loss: 1.1410 - val_accuracy: 0.4925\n",
      "Epoch 3/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1137 - accuracy: 0.5169 - val_loss: 1.4532 - val_accuracy: 0.4130\n",
      "Epoch 4/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1379 - accuracy: 0.5066 - val_loss: 1.0850 - val_accuracy: 0.5345\n",
      "Epoch 5/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0417 - accuracy: 0.5511 - val_loss: 0.9801 - val_accuracy: 0.5535\n",
      "Epoch 6/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9716 - accuracy: 0.5730 - val_loss: 0.9526 - val_accuracy: 0.5755\n",
      "Epoch 7/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9803 - accuracy: 0.5692 - val_loss: 0.9754 - val_accuracy: 0.5770\n",
      "Epoch 8/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9704 - accuracy: 0.5732 - val_loss: 0.9229 - val_accuracy: 0.5935\n",
      "Epoch 9/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9353 - accuracy: 0.5889 - val_loss: 1.0471 - val_accuracy: 0.5405\n",
      "Epoch 10/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9575 - accuracy: 0.5785 - val_loss: 0.9409 - val_accuracy: 0.5900\n",
      "Epoch 11/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9201 - accuracy: 0.5905 - val_loss: 1.0284 - val_accuracy: 0.5360\n",
      "Epoch 12/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9299 - accuracy: 0.5921 - val_loss: 0.9201 - val_accuracy: 0.6070\n",
      "Epoch 13/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8932 - accuracy: 0.6044 - val_loss: 0.9096 - val_accuracy: 0.6000\n",
      "Epoch 14/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8980 - accuracy: 0.6062 - val_loss: 0.8969 - val_accuracy: 0.6080\n",
      "Epoch 15/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9140 - accuracy: 0.5970 - val_loss: 0.9064 - val_accuracy: 0.6145\n",
      "Epoch 16/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8928 - accuracy: 0.6054 - val_loss: 0.8633 - val_accuracy: 0.6245\n",
      "Epoch 17/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8735 - accuracy: 0.6161 - val_loss: 0.9044 - val_accuracy: 0.6150\n",
      "Epoch 18/30\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.8932 - accuracy: 0.6099 - val_loss: 0.8553 - val_accuracy: 0.6245\n",
      "Epoch 19/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8790 - accuracy: 0.6136 - val_loss: 0.8831 - val_accuracy: 0.5995\n",
      "Epoch 20/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8766 - accuracy: 0.6146 - val_loss: 0.9518 - val_accuracy: 0.5920\n",
      "Epoch 21/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8870 - accuracy: 0.6044 - val_loss: 0.8582 - val_accuracy: 0.6140\n",
      "Epoch 22/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8685 - accuracy: 0.6219 - val_loss: 1.0307 - val_accuracy: 0.5835\n",
      "Epoch 23/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8985 - accuracy: 0.6033 - val_loss: 0.8481 - val_accuracy: 0.6420\n",
      "Epoch 24/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8348 - accuracy: 0.6339 - val_loss: 0.8845 - val_accuracy: 0.6355\n",
      "Epoch 25/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8895 - accuracy: 0.6100 - val_loss: 1.0088 - val_accuracy: 0.5720\n",
      "Epoch 26/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8465 - accuracy: 0.6300 - val_loss: 0.8208 - val_accuracy: 0.6415\n",
      "Epoch 27/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8678 - accuracy: 0.6179 - val_loss: 0.9083 - val_accuracy: 0.6070\n",
      "Epoch 28/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8451 - accuracy: 0.6277 - val_loss: 0.8220 - val_accuracy: 0.6535\n",
      "Epoch 29/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8378 - accuracy: 0.6344 - val_loss: 0.8188 - val_accuracy: 0.6435\n",
      "Epoch 30/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8244 - accuracy: 0.6376 - val_loss: 0.8759 - val_accuracy: 0.6255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x197c8a2cb10>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=30, batch_size=64, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 705us/step - loss: 0.8759 - accuracy: 0.6255\n",
      "Accuracy on the test set: 0.6255000233650208\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(X_test, y_test)[1]\n",
    "print(f\"Accuracy on the test set: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(df['race'].unique()), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_scheduler(epoch):\n",
    "    return 1e-3 * 0.9 ** epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=1e-3)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = LearningRateScheduler(lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 1.8565 - accuracy: 0.2680 - val_loss: 1.4438 - val_accuracy: 0.3980 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.5578 - accuracy: 0.3561 - val_loss: 1.2096 - val_accuracy: 0.4705 - lr: 9.0000e-04\n",
      "Epoch 3/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.3340 - accuracy: 0.4232 - val_loss: 1.2092 - val_accuracy: 0.4940 - lr: 8.1000e-04\n",
      "Epoch 4/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2291 - accuracy: 0.4703 - val_loss: 1.1000 - val_accuracy: 0.5380 - lr: 7.2900e-04\n",
      "Epoch 5/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1540 - accuracy: 0.4936 - val_loss: 1.1297 - val_accuracy: 0.5280 - lr: 6.5610e-04\n",
      "Epoch 6/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0807 - accuracy: 0.5324 - val_loss: 0.9331 - val_accuracy: 0.5880 - lr: 5.9049e-04\n",
      "Epoch 7/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0581 - accuracy: 0.5491 - val_loss: 0.9756 - val_accuracy: 0.5760 - lr: 5.3144e-04\n",
      "Epoch 8/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0233 - accuracy: 0.5584 - val_loss: 0.9429 - val_accuracy: 0.5825 - lr: 4.7830e-04\n",
      "Epoch 9/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0056 - accuracy: 0.5575 - val_loss: 0.9246 - val_accuracy: 0.5835 - lr: 4.3047e-04\n",
      "Epoch 10/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9894 - accuracy: 0.5684 - val_loss: 0.9191 - val_accuracy: 0.5925 - lr: 3.8742e-04\n",
      "Epoch 11/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9646 - accuracy: 0.5734 - val_loss: 1.0362 - val_accuracy: 0.5625 - lr: 3.4868e-04\n",
      "Epoch 12/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9650 - accuracy: 0.5734 - val_loss: 0.8960 - val_accuracy: 0.6010 - lr: 3.1381e-04\n",
      "Epoch 13/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9475 - accuracy: 0.5845 - val_loss: 0.9163 - val_accuracy: 0.5860 - lr: 2.8243e-04\n",
      "Epoch 14/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9376 - accuracy: 0.5890 - val_loss: 0.8787 - val_accuracy: 0.6035 - lr: 2.5419e-04\n",
      "Epoch 15/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9394 - accuracy: 0.5825 - val_loss: 0.9162 - val_accuracy: 0.5800 - lr: 2.2877e-04\n",
      "Epoch 16/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9245 - accuracy: 0.5867 - val_loss: 0.8824 - val_accuracy: 0.6105 - lr: 2.0589e-04\n",
      "Epoch 17/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9145 - accuracy: 0.5974 - val_loss: 0.8694 - val_accuracy: 0.6095 - lr: 1.8530e-04\n",
      "Epoch 18/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9199 - accuracy: 0.5863 - val_loss: 0.9108 - val_accuracy: 0.5950 - lr: 1.6677e-04\n",
      "Epoch 19/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9084 - accuracy: 0.5951 - val_loss: 0.8676 - val_accuracy: 0.6090 - lr: 1.5009e-04\n",
      "Epoch 20/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9183 - accuracy: 0.5947 - val_loss: 0.8728 - val_accuracy: 0.6070 - lr: 1.3509e-04\n",
      "Epoch 21/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8976 - accuracy: 0.6019 - val_loss: 0.8660 - val_accuracy: 0.6140 - lr: 1.2158e-04\n",
      "Epoch 22/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8975 - accuracy: 0.6000 - val_loss: 0.8589 - val_accuracy: 0.6160 - lr: 1.0942e-04\n",
      "Epoch 23/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8894 - accuracy: 0.6068 - val_loss: 0.8559 - val_accuracy: 0.6160 - lr: 9.8477e-05\n",
      "Epoch 24/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8834 - accuracy: 0.6127 - val_loss: 0.8583 - val_accuracy: 0.6160 - lr: 8.8629e-05\n",
      "Epoch 25/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8824 - accuracy: 0.6136 - val_loss: 0.8641 - val_accuracy: 0.6110 - lr: 7.9766e-05\n",
      "Epoch 26/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8881 - accuracy: 0.6080 - val_loss: 0.8529 - val_accuracy: 0.6135 - lr: 7.1790e-05\n",
      "Epoch 27/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8844 - accuracy: 0.6140 - val_loss: 0.8522 - val_accuracy: 0.6185 - lr: 6.4611e-05\n",
      "Epoch 28/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8807 - accuracy: 0.6085 - val_loss: 0.8545 - val_accuracy: 0.6190 - lr: 5.8150e-05\n",
      "Epoch 29/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8792 - accuracy: 0.6106 - val_loss: 0.8590 - val_accuracy: 0.6125 - lr: 5.2335e-05\n",
      "Epoch 30/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8724 - accuracy: 0.6183 - val_loss: 0.8625 - val_accuracy: 0.6035 - lr: 4.7101e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x197c8a59a50>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=30, batch_size=64, validation_data=(X_test, y_test),callbacks=[lr_schedule])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 654us/step - loss: 0.8625 - accuracy: 0.6035\n",
      "Accuracy on the test set: 0.6035000085830688\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(X_test, y_test)[1]\n",
    "print(f\"Accuracy on the test set: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32, input_dim = X_train.shape[1] ,activation = \"relu\"),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(df['race'].unique()), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['race'] = label_encoder.fit_transform(df['race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"race\",axis=1)\n",
    "y = df[\"race\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 1.5392 - accuracy: 0.3453 - val_loss: 1.4669 - val_accuracy: 0.3435\n",
      "Epoch 2/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1772 - accuracy: 0.4916 - val_loss: 1.0439 - val_accuracy: 0.5350\n",
      "Epoch 3/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9942 - accuracy: 0.5688 - val_loss: 1.0210 - val_accuracy: 0.5400\n",
      "Epoch 4/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9606 - accuracy: 0.5850 - val_loss: 0.9429 - val_accuracy: 0.5830\n",
      "Epoch 5/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9987 - accuracy: 0.5638 - val_loss: 0.9173 - val_accuracy: 0.6060\n",
      "Epoch 6/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9248 - accuracy: 0.5871 - val_loss: 0.9644 - val_accuracy: 0.5730\n",
      "Epoch 7/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9087 - accuracy: 0.5982 - val_loss: 0.9208 - val_accuracy: 0.6010\n",
      "Epoch 8/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9254 - accuracy: 0.5956 - val_loss: 0.9554 - val_accuracy: 0.5700\n",
      "Epoch 9/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8746 - accuracy: 0.6209 - val_loss: 0.9140 - val_accuracy: 0.6040\n",
      "Epoch 10/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8835 - accuracy: 0.6094 - val_loss: 0.8773 - val_accuracy: 0.6225\n",
      "Epoch 11/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8727 - accuracy: 0.6135 - val_loss: 0.9597 - val_accuracy: 0.5900\n",
      "Epoch 12/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8672 - accuracy: 0.6186 - val_loss: 0.8598 - val_accuracy: 0.6335\n",
      "Epoch 13/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8524 - accuracy: 0.6338 - val_loss: 0.8707 - val_accuracy: 0.6175\n",
      "Epoch 14/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8810 - accuracy: 0.6126 - val_loss: 0.9198 - val_accuracy: 0.6005\n",
      "Epoch 15/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8530 - accuracy: 0.6261 - val_loss: 0.8705 - val_accuracy: 0.6330\n",
      "Epoch 16/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8516 - accuracy: 0.6323 - val_loss: 0.8498 - val_accuracy: 0.6370\n",
      "Epoch 17/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8436 - accuracy: 0.6338 - val_loss: 0.8518 - val_accuracy: 0.6460\n",
      "Epoch 18/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8695 - accuracy: 0.6223 - val_loss: 0.9047 - val_accuracy: 0.6050\n",
      "Epoch 19/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8568 - accuracy: 0.6284 - val_loss: 0.9071 - val_accuracy: 0.6025\n",
      "Epoch 20/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8392 - accuracy: 0.6365 - val_loss: 0.8783 - val_accuracy: 0.6075\n",
      "Epoch 21/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8386 - accuracy: 0.6304 - val_loss: 0.8244 - val_accuracy: 0.6555\n",
      "Epoch 22/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8187 - accuracy: 0.6461 - val_loss: 0.8214 - val_accuracy: 0.6460\n",
      "Epoch 23/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8283 - accuracy: 0.6300 - val_loss: 0.8582 - val_accuracy: 0.6425\n",
      "Epoch 24/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8200 - accuracy: 0.6423 - val_loss: 0.8415 - val_accuracy: 0.6260\n",
      "Epoch 25/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8337 - accuracy: 0.6284 - val_loss: 0.8395 - val_accuracy: 0.6400\n",
      "Epoch 26/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8258 - accuracy: 0.6396 - val_loss: 0.8324 - val_accuracy: 0.6385\n",
      "Epoch 27/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8396 - accuracy: 0.6280 - val_loss: 0.8387 - val_accuracy: 0.6330\n",
      "Epoch 28/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8225 - accuracy: 0.6394 - val_loss: 0.8451 - val_accuracy: 0.6400\n",
      "Epoch 29/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8622 - accuracy: 0.6214 - val_loss: 0.8423 - val_accuracy: 0.6475\n",
      "Epoch 30/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8220 - accuracy: 0.6414 - val_loss: 0.8306 - val_accuracy: 0.6410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x197ce365fd0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=30, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 735us/step - loss: 0.8306 - accuracy: 0.6410\n",
      "Accuracy on the test set: 0.640999972820282\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(X_test, y_test)[1]\n",
    "print(f\"Accuracy on the test set: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df_2['race'] = label_encoder.fit_transform(df['race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_2.drop(\"race\",axis=1)\n",
    "y = df_2[\"race\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3943.0361 - accuracy: 0.3935 - val_loss: 7.7716 - val_accuracy: 0.4285\n",
      "Epoch 2/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 5.2724 - accuracy: 0.4354 - val_loss: 2.3080 - val_accuracy: 0.4730\n",
      "Epoch 3/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2.5194 - accuracy: 0.4471 - val_loss: 2.1173 - val_accuracy: 0.4790\n",
      "Epoch 4/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.8613 - accuracy: 0.4681 - val_loss: 1.6902 - val_accuracy: 0.4470\n",
      "Epoch 5/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.4652 - accuracy: 0.4952 - val_loss: 1.4929 - val_accuracy: 0.4630\n",
      "Epoch 6/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.4006 - accuracy: 0.5126 - val_loss: 1.5410 - val_accuracy: 0.5110\n",
      "Epoch 7/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.3433 - accuracy: 0.5124 - val_loss: 1.2047 - val_accuracy: 0.4895\n",
      "Epoch 8/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.3930 - accuracy: 0.5126 - val_loss: 1.1151 - val_accuracy: 0.5585\n",
      "Epoch 9/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.5603 - accuracy: 0.5010 - val_loss: 1.2585 - val_accuracy: 0.5505\n",
      "Epoch 10/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.3643 - accuracy: 0.5169 - val_loss: 1.3699 - val_accuracy: 0.4670\n",
      "Epoch 11/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2140 - accuracy: 0.5428 - val_loss: 1.2024 - val_accuracy: 0.5195\n",
      "Epoch 12/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1752 - accuracy: 0.5362 - val_loss: 1.0766 - val_accuracy: 0.5485\n",
      "Epoch 13/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2477 - accuracy: 0.5378 - val_loss: 1.2637 - val_accuracy: 0.5420\n",
      "Epoch 14/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2106 - accuracy: 0.5372 - val_loss: 1.3769 - val_accuracy: 0.5475\n",
      "Epoch 15/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1354 - accuracy: 0.5551 - val_loss: 1.1135 - val_accuracy: 0.5515\n",
      "Epoch 16/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1410 - accuracy: 0.5491 - val_loss: 1.1311 - val_accuracy: 0.5230\n",
      "Epoch 17/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1348 - accuracy: 0.5476 - val_loss: 1.0456 - val_accuracy: 0.5910\n",
      "Epoch 18/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2409 - accuracy: 0.5315 - val_loss: 1.0319 - val_accuracy: 0.5660\n",
      "Epoch 19/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1099 - accuracy: 0.5615 - val_loss: 1.0303 - val_accuracy: 0.5665\n",
      "Epoch 20/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1114 - accuracy: 0.5602 - val_loss: 1.2396 - val_accuracy: 0.5165\n",
      "Epoch 21/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0598 - accuracy: 0.5654 - val_loss: 1.0773 - val_accuracy: 0.5510\n",
      "Epoch 22/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0547 - accuracy: 0.5645 - val_loss: 1.0710 - val_accuracy: 0.5510\n",
      "Epoch 23/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0661 - accuracy: 0.5570 - val_loss: 1.1185 - val_accuracy: 0.5455\n",
      "Epoch 24/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0623 - accuracy: 0.5654 - val_loss: 1.0021 - val_accuracy: 0.5855\n",
      "Epoch 25/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0360 - accuracy: 0.5636 - val_loss: 1.0496 - val_accuracy: 0.5505\n",
      "Epoch 26/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0086 - accuracy: 0.5730 - val_loss: 0.9973 - val_accuracy: 0.5790\n",
      "Epoch 27/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9996 - accuracy: 0.5771 - val_loss: 1.0995 - val_accuracy: 0.5675\n",
      "Epoch 28/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1990 - accuracy: 0.5494 - val_loss: 1.1336 - val_accuracy: 0.5495\n",
      "Epoch 29/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0591 - accuracy: 0.5608 - val_loss: 1.0423 - val_accuracy: 0.6000\n",
      "Epoch 30/30\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0656 - accuracy: 0.5523 - val_loss: 1.0176 - val_accuracy: 0.5580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x197c72b1310>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=30, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 750us/step - loss: 1.0176 - accuracy: 0.5580\n",
      "Accuracy on the test set: 0.5580000281333923\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(X_test, y_test)[1]\n",
    "print(f\"Accuracy on the test set: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 1s 3ms/step - loss: 2.6625 - accuracy: 0.1972 - val_loss: 1.8290 - val_accuracy: 0.3906\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8545 - accuracy: 0.3184 - val_loss: 1.4210 - val_accuracy: 0.4519\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.5434 - accuracy: 0.3883 - val_loss: 1.1576 - val_accuracy: 0.4812\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.3835 - accuracy: 0.4127 - val_loss: 1.0750 - val_accuracy: 0.4913\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.3011 - accuracy: 0.4278 - val_loss: 1.0520 - val_accuracy: 0.5050\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.2600 - accuracy: 0.4405 - val_loss: 1.0458 - val_accuracy: 0.5006\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.2258 - accuracy: 0.4473 - val_loss: 1.0429 - val_accuracy: 0.5013\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.2036 - accuracy: 0.4461 - val_loss: 1.0405 - val_accuracy: 0.4963\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1801 - accuracy: 0.4588 - val_loss: 1.0367 - val_accuracy: 0.5581\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1669 - accuracy: 0.4559 - val_loss: 1.0338 - val_accuracy: 0.5631\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1623 - accuracy: 0.4719 - val_loss: 1.0275 - val_accuracy: 0.5225\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1500 - accuracy: 0.4703 - val_loss: 1.0240 - val_accuracy: 0.5719\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1375 - accuracy: 0.4753 - val_loss: 1.0206 - val_accuracy: 0.5769\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1283 - accuracy: 0.4836 - val_loss: 1.0142 - val_accuracy: 0.5925\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1221 - accuracy: 0.4967 - val_loss: 1.0027 - val_accuracy: 0.5794\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1186 - accuracy: 0.4908 - val_loss: 0.9937 - val_accuracy: 0.5769\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1022 - accuracy: 0.5039 - val_loss: 0.9834 - val_accuracy: 0.5875\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0886 - accuracy: 0.5097 - val_loss: 0.9696 - val_accuracy: 0.5825\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0776 - accuracy: 0.5084 - val_loss: 0.9572 - val_accuracy: 0.5969\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0567 - accuracy: 0.5378 - val_loss: 0.9337 - val_accuracy: 0.6106\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0387 - accuracy: 0.5564 - val_loss: 0.8926 - val_accuracy: 0.6306\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0207 - accuracy: 0.5698 - val_loss: 0.8615 - val_accuracy: 0.6431\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0082 - accuracy: 0.5767 - val_loss: 0.8447 - val_accuracy: 0.6419\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0000 - accuracy: 0.5802 - val_loss: 0.8732 - val_accuracy: 0.6169\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9801 - accuracy: 0.5870 - val_loss: 0.8281 - val_accuracy: 0.6519\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9738 - accuracy: 0.5978 - val_loss: 0.8299 - val_accuracy: 0.6431\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9635 - accuracy: 0.5900 - val_loss: 0.8221 - val_accuracy: 0.6475\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9526 - accuracy: 0.6020 - val_loss: 0.8189 - val_accuracy: 0.6531\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9521 - accuracy: 0.6016 - val_loss: 0.8236 - val_accuracy: 0.6469\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9421 - accuracy: 0.6073 - val_loss: 0.8152 - val_accuracy: 0.6544\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9453 - accuracy: 0.6070 - val_loss: 0.8138 - val_accuracy: 0.6506\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9360 - accuracy: 0.5973 - val_loss: 0.8201 - val_accuracy: 0.6431\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9408 - accuracy: 0.6056 - val_loss: 0.8192 - val_accuracy: 0.6519\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9348 - accuracy: 0.6156 - val_loss: 0.8135 - val_accuracy: 0.6562\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9310 - accuracy: 0.6147 - val_loss: 0.8180 - val_accuracy: 0.6556\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9333 - accuracy: 0.6181 - val_loss: 0.8220 - val_accuracy: 0.6556\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9159 - accuracy: 0.6211 - val_loss: 0.8169 - val_accuracy: 0.6488\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9220 - accuracy: 0.6169 - val_loss: 0.8237 - val_accuracy: 0.6450\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9213 - accuracy: 0.6223 - val_loss: 0.8122 - val_accuracy: 0.6494\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9244 - accuracy: 0.6202 - val_loss: 0.8093 - val_accuracy: 0.6575\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9122 - accuracy: 0.6212 - val_loss: 0.8100 - val_accuracy: 0.6550\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9184 - accuracy: 0.6217 - val_loss: 0.8165 - val_accuracy: 0.6550\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9074 - accuracy: 0.6183 - val_loss: 0.8043 - val_accuracy: 0.6575\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9109 - accuracy: 0.6288 - val_loss: 0.8054 - val_accuracy: 0.6469\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8954 - accuracy: 0.6311 - val_loss: 0.8059 - val_accuracy: 0.6481\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9062 - accuracy: 0.6230 - val_loss: 0.8151 - val_accuracy: 0.6525\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9048 - accuracy: 0.6270 - val_loss: 0.8104 - val_accuracy: 0.6519\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9106 - accuracy: 0.6267 - val_loss: 0.8164 - val_accuracy: 0.6531\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9018 - accuracy: 0.6270 - val_loss: 0.8078 - val_accuracy: 0.6456\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9082 - accuracy: 0.6236 - val_loss: 0.8101 - val_accuracy: 0.6494\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8948 - accuracy: 0.6284 - val_loss: 0.8082 - val_accuracy: 0.6513\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9020 - accuracy: 0.6233 - val_loss: 0.8028 - val_accuracy: 0.6562\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9014 - accuracy: 0.6272 - val_loss: 0.8065 - val_accuracy: 0.6531\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8890 - accuracy: 0.6278 - val_loss: 0.8048 - val_accuracy: 0.6556\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8957 - accuracy: 0.6273 - val_loss: 0.8024 - val_accuracy: 0.6562\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8924 - accuracy: 0.6347 - val_loss: 0.8016 - val_accuracy: 0.6600\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8997 - accuracy: 0.6269 - val_loss: 0.8033 - val_accuracy: 0.6531\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8890 - accuracy: 0.6355 - val_loss: 0.7995 - val_accuracy: 0.6550\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8979 - accuracy: 0.6258 - val_loss: 0.8095 - val_accuracy: 0.6494\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8972 - accuracy: 0.6327 - val_loss: 0.8021 - val_accuracy: 0.6519\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8834 - accuracy: 0.6372 - val_loss: 0.8125 - val_accuracy: 0.6425\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8952 - accuracy: 0.6269 - val_loss: 0.7945 - val_accuracy: 0.6556\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8814 - accuracy: 0.6369 - val_loss: 0.7975 - val_accuracy: 0.6612\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8888 - accuracy: 0.6319 - val_loss: 0.7993 - val_accuracy: 0.6494\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8884 - accuracy: 0.6298 - val_loss: 0.7968 - val_accuracy: 0.6575\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8774 - accuracy: 0.6389 - val_loss: 0.7944 - val_accuracy: 0.6625\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8816 - accuracy: 0.6277 - val_loss: 0.8005 - val_accuracy: 0.6581\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8896 - accuracy: 0.6286 - val_loss: 0.7986 - val_accuracy: 0.6600\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8939 - accuracy: 0.6261 - val_loss: 0.7984 - val_accuracy: 0.6600\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8764 - accuracy: 0.6366 - val_loss: 0.7981 - val_accuracy: 0.6631\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8815 - accuracy: 0.6369 - val_loss: 0.7951 - val_accuracy: 0.6531\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8752 - accuracy: 0.6414 - val_loss: 0.7892 - val_accuracy: 0.6650\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8726 - accuracy: 0.6420 - val_loss: 0.7920 - val_accuracy: 0.6644\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8831 - accuracy: 0.6261 - val_loss: 0.8034 - val_accuracy: 0.6525\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8850 - accuracy: 0.6303 - val_loss: 0.7912 - val_accuracy: 0.6556\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8779 - accuracy: 0.6300 - val_loss: 0.7894 - val_accuracy: 0.6525\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8774 - accuracy: 0.6348 - val_loss: 0.7890 - val_accuracy: 0.6619\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8736 - accuracy: 0.6367 - val_loss: 0.7929 - val_accuracy: 0.6550\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8604 - accuracy: 0.6436 - val_loss: 0.7880 - val_accuracy: 0.6681\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8760 - accuracy: 0.6305 - val_loss: 0.7924 - val_accuracy: 0.6562\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8727 - accuracy: 0.6342 - val_loss: 0.7906 - val_accuracy: 0.6600\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8797 - accuracy: 0.6347 - val_loss: 0.7816 - val_accuracy: 0.6625\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8774 - accuracy: 0.6348 - val_loss: 0.7913 - val_accuracy: 0.6556\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8566 - accuracy: 0.6406 - val_loss: 0.7844 - val_accuracy: 0.6594\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8673 - accuracy: 0.6427 - val_loss: 0.8113 - val_accuracy: 0.6550\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8795 - accuracy: 0.6344 - val_loss: 0.7924 - val_accuracy: 0.6575\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8713 - accuracy: 0.6419 - val_loss: 0.7940 - val_accuracy: 0.6606\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8687 - accuracy: 0.6381 - val_loss: 0.7810 - val_accuracy: 0.6550\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8765 - accuracy: 0.6331 - val_loss: 0.7795 - val_accuracy: 0.6594\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8682 - accuracy: 0.6408 - val_loss: 0.7792 - val_accuracy: 0.6594\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8674 - accuracy: 0.6381 - val_loss: 0.7836 - val_accuracy: 0.6612\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8570 - accuracy: 0.6414 - val_loss: 0.8001 - val_accuracy: 0.6481\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8568 - accuracy: 0.6436 - val_loss: 0.7804 - val_accuracy: 0.6669\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8655 - accuracy: 0.6388 - val_loss: 0.7831 - val_accuracy: 0.6538\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8607 - accuracy: 0.6347 - val_loss: 0.7801 - val_accuracy: 0.6619\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8574 - accuracy: 0.6414 - val_loss: 0.7766 - val_accuracy: 0.6656\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8633 - accuracy: 0.6444 - val_loss: 0.7852 - val_accuracy: 0.6562\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8636 - accuracy: 0.6367 - val_loss: 0.7688 - val_accuracy: 0.6650\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8527 - accuracy: 0.6395 - val_loss: 0.7857 - val_accuracy: 0.6519\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8507 - accuracy: 0.6436 - val_loss: 0.7895 - val_accuracy: 0.6569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x197ce37ce10>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['race'] = label_encoder.fit_transform(df['race'])\n",
    "\n",
    "X = df.drop('race', axis=1)  \n",
    "y = df['race']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "\n",
    "    tf.keras.layers.Dense(256, input_dim=X_train.shape[1], activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "    tf.keras.layers.Dense(128, input_dim=X_train.shape[1], activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "    tf.keras.layers.Dense(len(df['race'].unique()), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 734us/step - loss: 0.7996 - accuracy: 0.6730\n",
      "Mean Squared Error on Test Set: 0.7995953559875488\n",
      "Accuracy on the test set: 0.6729999780654907\n",
      "63/63 [==============================] - 0s 629us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss,accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Mean Squared Error on Test Set: {loss}')\n",
    "print(f\"Accuracy on the test set: {accuracy}\")\n",
    "\n",
    "predictions = model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
