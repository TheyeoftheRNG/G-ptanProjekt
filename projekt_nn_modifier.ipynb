{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\marto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>speed</th>\n",
       "      <th>strength</th>\n",
       "      <th>dexterity</th>\n",
       "      <th>constitution</th>\n",
       "      <th>intelligence</th>\n",
       "      <th>wisdom</th>\n",
       "      <th>charisma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dragonborn</td>\n",
       "      <td>79</td>\n",
       "      <td>279</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dragonborn</td>\n",
       "      <td>79</td>\n",
       "      <td>331</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dragonborn</td>\n",
       "      <td>71</td>\n",
       "      <td>230</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dragonborn</td>\n",
       "      <td>75</td>\n",
       "      <td>265</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dragonborn</td>\n",
       "      <td>72</td>\n",
       "      <td>229</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>tiefling</td>\n",
       "      <td>63</td>\n",
       "      <td>146</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>tiefling</td>\n",
       "      <td>72</td>\n",
       "      <td>230</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>tiefling</td>\n",
       "      <td>66</td>\n",
       "      <td>137</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>tiefling</td>\n",
       "      <td>68</td>\n",
       "      <td>143</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>tiefling</td>\n",
       "      <td>70</td>\n",
       "      <td>201</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            race  height  weight  speed  strength  dexterity  constitution  \\\n",
       "0     dragonborn      79     279     30        14         15            12   \n",
       "1     dragonborn      79     331     30        11         11            11   \n",
       "2     dragonborn      71     230     30        14         16            11   \n",
       "3     dragonborn      75     265     30         8         19             7   \n",
       "4     dragonborn      72     229     30         8         17            14   \n",
       "...          ...     ...     ...    ...       ...        ...           ...   \n",
       "9995    tiefling      63     146     30        13         18            17   \n",
       "9996    tiefling      72     230     30         8         14            13   \n",
       "9997    tiefling      66     137     30         4          5            16   \n",
       "9998    tiefling      68     143     30        12         16            12   \n",
       "9999    tiefling      70     201     30        16         17            15   \n",
       "\n",
       "      intelligence  wisdom  charisma  \n",
       "0                7      13        16  \n",
       "1               13      13        17  \n",
       "2               13      10        18  \n",
       "3               10      13        16  \n",
       "4               14      10         9  \n",
       "...            ...     ...       ...  \n",
       "9995            13      15        13  \n",
       "9996             6      14        20  \n",
       "9997            12      12        15  \n",
       "9998            15       9        16  \n",
       "9999            12      13        13  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"stats.csv\")\n",
    "\n",
    "df\n",
    "pd.set_option('display.max_rows', 60)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    " \n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>speed</th>\n",
       "      <th>strength</th>\n",
       "      <th>dexterity</th>\n",
       "      <th>constitution</th>\n",
       "      <th>intelligence</th>\n",
       "      <th>wisdom</th>\n",
       "      <th>charisma</th>\n",
       "      <th>strength_modifier</th>\n",
       "      <th>dexterity_modifier</th>\n",
       "      <th>constitution_modifier</th>\n",
       "      <th>intelligence_modifier</th>\n",
       "      <th>wisdom_modifier</th>\n",
       "      <th>charisma_modifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dragonborn</td>\n",
       "      <td>79</td>\n",
       "      <td>279</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dragonborn</td>\n",
       "      <td>79</td>\n",
       "      <td>331</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dragonborn</td>\n",
       "      <td>71</td>\n",
       "      <td>230</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dragonborn</td>\n",
       "      <td>75</td>\n",
       "      <td>265</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dragonborn</td>\n",
       "      <td>72</td>\n",
       "      <td>229</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>tiefling</td>\n",
       "      <td>63</td>\n",
       "      <td>146</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>tiefling</td>\n",
       "      <td>72</td>\n",
       "      <td>230</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>tiefling</td>\n",
       "      <td>66</td>\n",
       "      <td>137</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>tiefling</td>\n",
       "      <td>68</td>\n",
       "      <td>143</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>tiefling</td>\n",
       "      <td>70</td>\n",
       "      <td>201</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            race  height  weight  speed  strength  dexterity  constitution  \\\n",
       "0     dragonborn      79     279     30        14         15            12   \n",
       "1     dragonborn      79     331     30        11         11            11   \n",
       "2     dragonborn      71     230     30        14         16            11   \n",
       "3     dragonborn      75     265     30         8         19             7   \n",
       "4     dragonborn      72     229     30         8         17            14   \n",
       "...          ...     ...     ...    ...       ...        ...           ...   \n",
       "9995    tiefling      63     146     30        13         18            17   \n",
       "9996    tiefling      72     230     30         8         14            13   \n",
       "9997    tiefling      66     137     30         4          5            16   \n",
       "9998    tiefling      68     143     30        12         16            12   \n",
       "9999    tiefling      70     201     30        16         17            15   \n",
       "\n",
       "      intelligence  wisdom  charisma  strength_modifier  dexterity_modifier  \\\n",
       "0                7      13        16                  2                   2   \n",
       "1               13      13        17                  0                   0   \n",
       "2               13      10        18                  2                   3   \n",
       "3               10      13        16                 -1                   4   \n",
       "4               14      10         9                 -1                   3   \n",
       "...            ...     ...       ...                ...                 ...   \n",
       "9995            13      15        13                  1                   4   \n",
       "9996             6      14        20                 -1                   2   \n",
       "9997            12      12        15                 -3                  -3   \n",
       "9998            15       9        16                  1                   3   \n",
       "9999            12      13        13                  3                   3   \n",
       "\n",
       "      constitution_modifier  intelligence_modifier  wisdom_modifier  \\\n",
       "0                         1                     -2                1   \n",
       "1                         0                      1                1   \n",
       "2                         0                      1                0   \n",
       "3                        -2                      0                1   \n",
       "4                         2                      2                0   \n",
       "...                     ...                    ...              ...   \n",
       "9995                      3                      1                2   \n",
       "9996                      1                     -2                2   \n",
       "9997                      3                      1                1   \n",
       "9998                      1                      2               -1   \n",
       "9999                      2                      1                1   \n",
       "\n",
       "      charisma_modifier  \n",
       "0                     3  \n",
       "1                     3  \n",
       "2                     4  \n",
       "3                     3  \n",
       "4                    -1  \n",
       "...                 ...  \n",
       "9995                  1  \n",
       "9996                  5  \n",
       "9997                  2  \n",
       "9998                  3  \n",
       "9999                  1  \n",
       "\n",
       "[10000 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ability_score_columns = ['strength', 'dexterity', 'constitution', 'intelligence', 'wisdom', 'charisma']\n",
    "df_6 = df.copy()\n",
    "for column in ability_score_columns:\n",
    "    df_6[column + '_modifier'] = (df[column] - 10) // 2\n",
    "\n",
    "\n",
    "df_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df_6['race'] = label_encoder.fit_transform(df_6['race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_6.drop(\"race\",axis=1)\n",
    "y = df_6[\"race\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\marto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\marto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\Users\\marto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\marto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "100/100 [==============================] - 2s 3ms/step - loss: 2.6747 - accuracy: 0.1594 - val_loss: 1.9978 - val_accuracy: 0.2512\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9726 - accuracy: 0.2788 - val_loss: 1.5580 - val_accuracy: 0.4112\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.6049 - accuracy: 0.3684 - val_loss: 1.2489 - val_accuracy: 0.4956\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.4330 - accuracy: 0.4048 - val_loss: 1.1217 - val_accuracy: 0.5319\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.3305 - accuracy: 0.4191 - val_loss: 1.0806 - val_accuracy: 0.5294\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.2806 - accuracy: 0.4348 - val_loss: 1.0675 - val_accuracy: 0.5319\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.2473 - accuracy: 0.4342 - val_loss: 1.0611 - val_accuracy: 0.5300\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.2111 - accuracy: 0.4462 - val_loss: 1.0542 - val_accuracy: 0.5175\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1960 - accuracy: 0.4541 - val_loss: 1.0524 - val_accuracy: 0.5494\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1785 - accuracy: 0.4630 - val_loss: 1.0494 - val_accuracy: 0.5444\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1651 - accuracy: 0.4619 - val_loss: 1.0503 - val_accuracy: 0.4956\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1549 - accuracy: 0.4527 - val_loss: 1.0449 - val_accuracy: 0.5375\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1445 - accuracy: 0.4686 - val_loss: 1.0342 - val_accuracy: 0.5469\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1352 - accuracy: 0.4737 - val_loss: 1.0309 - val_accuracy: 0.5519\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1406 - accuracy: 0.4745 - val_loss: 1.0277 - val_accuracy: 0.5487\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1269 - accuracy: 0.4784 - val_loss: 1.0271 - val_accuracy: 0.5525\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1165 - accuracy: 0.4863 - val_loss: 1.0221 - val_accuracy: 0.5650\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1169 - accuracy: 0.4852 - val_loss: 1.0139 - val_accuracy: 0.5675\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1033 - accuracy: 0.4947 - val_loss: 1.0069 - val_accuracy: 0.5644\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1014 - accuracy: 0.5048 - val_loss: 1.0036 - val_accuracy: 0.5625\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0975 - accuracy: 0.5070 - val_loss: 0.9935 - val_accuracy: 0.5806\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0975 - accuracy: 0.5133 - val_loss: 0.9816 - val_accuracy: 0.5813\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0743 - accuracy: 0.5270 - val_loss: 0.9569 - val_accuracy: 0.5969\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0634 - accuracy: 0.5383 - val_loss: 0.9409 - val_accuracy: 0.6106\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0592 - accuracy: 0.5412 - val_loss: 0.9242 - val_accuracy: 0.6050\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0463 - accuracy: 0.5528 - val_loss: 0.8970 - val_accuracy: 0.6306\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0271 - accuracy: 0.5598 - val_loss: 0.8916 - val_accuracy: 0.6319\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0118 - accuracy: 0.5691 - val_loss: 0.8810 - val_accuracy: 0.6269\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9977 - accuracy: 0.5850 - val_loss: 0.8553 - val_accuracy: 0.6413\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9863 - accuracy: 0.5864 - val_loss: 0.8551 - val_accuracy: 0.6419\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9903 - accuracy: 0.5897 - val_loss: 0.8462 - val_accuracy: 0.6388\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9672 - accuracy: 0.5978 - val_loss: 0.8340 - val_accuracy: 0.6481\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9730 - accuracy: 0.5964 - val_loss: 0.8423 - val_accuracy: 0.6425\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9581 - accuracy: 0.6050 - val_loss: 0.8231 - val_accuracy: 0.6481\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9595 - accuracy: 0.6081 - val_loss: 0.8217 - val_accuracy: 0.6475\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9669 - accuracy: 0.6067 - val_loss: 0.8228 - val_accuracy: 0.6481\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9417 - accuracy: 0.6122 - val_loss: 0.8202 - val_accuracy: 0.6569\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9472 - accuracy: 0.6095 - val_loss: 0.8178 - val_accuracy: 0.6506\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9388 - accuracy: 0.6177 - val_loss: 0.8269 - val_accuracy: 0.6438\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9326 - accuracy: 0.6150 - val_loss: 0.8135 - val_accuracy: 0.6550\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9434 - accuracy: 0.6161 - val_loss: 0.8174 - val_accuracy: 0.6456\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9216 - accuracy: 0.6195 - val_loss: 0.8199 - val_accuracy: 0.6469\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9407 - accuracy: 0.6134 - val_loss: 0.8139 - val_accuracy: 0.6525\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9298 - accuracy: 0.6169 - val_loss: 0.8198 - val_accuracy: 0.6519\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9254 - accuracy: 0.6205 - val_loss: 0.8113 - val_accuracy: 0.6525\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9188 - accuracy: 0.6245 - val_loss: 0.8064 - val_accuracy: 0.6587\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9195 - accuracy: 0.6195 - val_loss: 0.8102 - val_accuracy: 0.6556\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9227 - accuracy: 0.6153 - val_loss: 0.8130 - val_accuracy: 0.6444\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9139 - accuracy: 0.6225 - val_loss: 0.8136 - val_accuracy: 0.6569\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9147 - accuracy: 0.6227 - val_loss: 0.8156 - val_accuracy: 0.6444\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9243 - accuracy: 0.6159 - val_loss: 0.8011 - val_accuracy: 0.6569\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9103 - accuracy: 0.6316 - val_loss: 0.8176 - val_accuracy: 0.6431\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9262 - accuracy: 0.6197 - val_loss: 0.8076 - val_accuracy: 0.6488\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9154 - accuracy: 0.6288 - val_loss: 0.8089 - val_accuracy: 0.6519\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9175 - accuracy: 0.6217 - val_loss: 0.8159 - val_accuracy: 0.6513\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9184 - accuracy: 0.6200 - val_loss: 0.8072 - val_accuracy: 0.6538\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9066 - accuracy: 0.6289 - val_loss: 0.8121 - val_accuracy: 0.6519\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9140 - accuracy: 0.6109 - val_loss: 0.8096 - val_accuracy: 0.6544\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9042 - accuracy: 0.6289 - val_loss: 0.8131 - val_accuracy: 0.6481\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8954 - accuracy: 0.6314 - val_loss: 0.8074 - val_accuracy: 0.6550\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8994 - accuracy: 0.6278 - val_loss: 0.8142 - val_accuracy: 0.6513\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9034 - accuracy: 0.6241 - val_loss: 0.8053 - val_accuracy: 0.6494\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8898 - accuracy: 0.6266 - val_loss: 0.8053 - val_accuracy: 0.6538\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9065 - accuracy: 0.6267 - val_loss: 0.8027 - val_accuracy: 0.6562\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8982 - accuracy: 0.6289 - val_loss: 0.7986 - val_accuracy: 0.6656\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8952 - accuracy: 0.6270 - val_loss: 0.8078 - val_accuracy: 0.6581\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8904 - accuracy: 0.6306 - val_loss: 0.7997 - val_accuracy: 0.6525\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8941 - accuracy: 0.6248 - val_loss: 0.8012 - val_accuracy: 0.6519\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8885 - accuracy: 0.6233 - val_loss: 0.8081 - val_accuracy: 0.6500\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8877 - accuracy: 0.6359 - val_loss: 0.7989 - val_accuracy: 0.6675\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8861 - accuracy: 0.6350 - val_loss: 0.8068 - val_accuracy: 0.6550\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8889 - accuracy: 0.6352 - val_loss: 0.8035 - val_accuracy: 0.6475\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8834 - accuracy: 0.6305 - val_loss: 0.8114 - val_accuracy: 0.6456\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8832 - accuracy: 0.6336 - val_loss: 0.8037 - val_accuracy: 0.6581\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8902 - accuracy: 0.6258 - val_loss: 0.8048 - val_accuracy: 0.6612\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8868 - accuracy: 0.6406 - val_loss: 0.8030 - val_accuracy: 0.6506\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8868 - accuracy: 0.6378 - val_loss: 0.8190 - val_accuracy: 0.6619\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8974 - accuracy: 0.6289 - val_loss: 0.8017 - val_accuracy: 0.6569\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8898 - accuracy: 0.6288 - val_loss: 0.7996 - val_accuracy: 0.6525\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8891 - accuracy: 0.6363 - val_loss: 0.7983 - val_accuracy: 0.6575\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8806 - accuracy: 0.6322 - val_loss: 0.8081 - val_accuracy: 0.6381\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8785 - accuracy: 0.6366 - val_loss: 0.8041 - val_accuracy: 0.6488\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8828 - accuracy: 0.6367 - val_loss: 0.7994 - val_accuracy: 0.6606\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8807 - accuracy: 0.6263 - val_loss: 0.7977 - val_accuracy: 0.6500\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8789 - accuracy: 0.6289 - val_loss: 0.7963 - val_accuracy: 0.6600\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8812 - accuracy: 0.6342 - val_loss: 0.7981 - val_accuracy: 0.6656\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8767 - accuracy: 0.6319 - val_loss: 0.7947 - val_accuracy: 0.6575\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8762 - accuracy: 0.6338 - val_loss: 0.7906 - val_accuracy: 0.6600\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8807 - accuracy: 0.6303 - val_loss: 0.8055 - val_accuracy: 0.6475\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8848 - accuracy: 0.6294 - val_loss: 0.7948 - val_accuracy: 0.6594\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8693 - accuracy: 0.6339 - val_loss: 0.7949 - val_accuracy: 0.6594\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8797 - accuracy: 0.6392 - val_loss: 0.7903 - val_accuracy: 0.6637\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8699 - accuracy: 0.6338 - val_loss: 0.7897 - val_accuracy: 0.6594\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8837 - accuracy: 0.6325 - val_loss: 0.7981 - val_accuracy: 0.6525\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8756 - accuracy: 0.6323 - val_loss: 0.7975 - val_accuracy: 0.6544\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8699 - accuracy: 0.6352 - val_loss: 0.7862 - val_accuracy: 0.6650\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8832 - accuracy: 0.6266 - val_loss: 0.7926 - val_accuracy: 0.6625\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8614 - accuracy: 0.6397 - val_loss: 0.7910 - val_accuracy: 0.6600\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8729 - accuracy: 0.6397 - val_loss: 0.8051 - val_accuracy: 0.6513\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8732 - accuracy: 0.6333 - val_loss: 0.7823 - val_accuracy: 0.6656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2722d52ae10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "\n",
    "    tf.keras.layers.Dense(256, input_dim=X_train.shape[1], activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "    tf.keras.layers.Dense(len(df['race'].unique()), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 968us/step - loss: 0.7995 - accuracy: 0.6685\n",
      "Mean Squared Error on Test Set: 0.7995193600654602\n",
      "Accuracy on the test set: 0.6685000061988831\n",
      "63/63 [==============================] - 0s 806us/step\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Mean Squared Error on Test Set: {loss}')\n",
    "print(f\"Accuracy on the test set: {accuracy}\")\n",
    "\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>speed</th>\n",
       "      <th>strength</th>\n",
       "      <th>dexterity</th>\n",
       "      <th>constitution</th>\n",
       "      <th>intelligence</th>\n",
       "      <th>wisdom</th>\n",
       "      <th>charisma</th>\n",
       "      <th>strength_modifier</th>\n",
       "      <th>dexterity_modifier</th>\n",
       "      <th>constitution_modifier</th>\n",
       "      <th>intelligence_modifier</th>\n",
       "      <th>wisdom_modifier</th>\n",
       "      <th>charisma_modifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>493039</td>\n",
       "      <td>21717639</td>\n",
       "      <td>27000</td>\n",
       "      <td>2744</td>\n",
       "      <td>3375</td>\n",
       "      <td>1728</td>\n",
       "      <td>343</td>\n",
       "      <td>2197</td>\n",
       "      <td>4096</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-8</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>493039</td>\n",
       "      <td>36264691</td>\n",
       "      <td>27000</td>\n",
       "      <td>1331</td>\n",
       "      <td>1331</td>\n",
       "      <td>1331</td>\n",
       "      <td>2197</td>\n",
       "      <td>2197</td>\n",
       "      <td>4913</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>357911</td>\n",
       "      <td>12167000</td>\n",
       "      <td>27000</td>\n",
       "      <td>2744</td>\n",
       "      <td>4096</td>\n",
       "      <td>1331</td>\n",
       "      <td>2197</td>\n",
       "      <td>1000</td>\n",
       "      <td>5832</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>421875</td>\n",
       "      <td>18609625</td>\n",
       "      <td>27000</td>\n",
       "      <td>512</td>\n",
       "      <td>6859</td>\n",
       "      <td>343</td>\n",
       "      <td>1000</td>\n",
       "      <td>2197</td>\n",
       "      <td>4096</td>\n",
       "      <td>-1</td>\n",
       "      <td>64</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>373248</td>\n",
       "      <td>12008989</td>\n",
       "      <td>27000</td>\n",
       "      <td>512</td>\n",
       "      <td>4913</td>\n",
       "      <td>2744</td>\n",
       "      <td>2744</td>\n",
       "      <td>1000</td>\n",
       "      <td>729</td>\n",
       "      <td>-1</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>8</td>\n",
       "      <td>250047</td>\n",
       "      <td>3112136</td>\n",
       "      <td>27000</td>\n",
       "      <td>2197</td>\n",
       "      <td>5832</td>\n",
       "      <td>4913</td>\n",
       "      <td>2197</td>\n",
       "      <td>3375</td>\n",
       "      <td>2197</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>8</td>\n",
       "      <td>373248</td>\n",
       "      <td>12167000</td>\n",
       "      <td>27000</td>\n",
       "      <td>512</td>\n",
       "      <td>2744</td>\n",
       "      <td>2197</td>\n",
       "      <td>216</td>\n",
       "      <td>2744</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-8</td>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>8</td>\n",
       "      <td>287496</td>\n",
       "      <td>2571353</td>\n",
       "      <td>27000</td>\n",
       "      <td>64</td>\n",
       "      <td>125</td>\n",
       "      <td>4096</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>3375</td>\n",
       "      <td>-27</td>\n",
       "      <td>-27</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>8</td>\n",
       "      <td>314432</td>\n",
       "      <td>2924207</td>\n",
       "      <td>27000</td>\n",
       "      <td>1728</td>\n",
       "      <td>4096</td>\n",
       "      <td>1728</td>\n",
       "      <td>3375</td>\n",
       "      <td>729</td>\n",
       "      <td>4096</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>8</td>\n",
       "      <td>343000</td>\n",
       "      <td>8120601</td>\n",
       "      <td>27000</td>\n",
       "      <td>4096</td>\n",
       "      <td>4913</td>\n",
       "      <td>3375</td>\n",
       "      <td>1728</td>\n",
       "      <td>2197</td>\n",
       "      <td>2197</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      race  height    weight  speed  strength  dexterity  constitution  \\\n",
       "0        0  493039  21717639  27000      2744       3375          1728   \n",
       "1        0  493039  36264691  27000      1331       1331          1331   \n",
       "2        0  357911  12167000  27000      2744       4096          1331   \n",
       "3        0  421875  18609625  27000       512       6859           343   \n",
       "4        0  373248  12008989  27000       512       4913          2744   \n",
       "...    ...     ...       ...    ...       ...        ...           ...   \n",
       "9995     8  250047   3112136  27000      2197       5832          4913   \n",
       "9996     8  373248  12167000  27000       512       2744          2197   \n",
       "9997     8  287496   2571353  27000        64        125          4096   \n",
       "9998     8  314432   2924207  27000      1728       4096          1728   \n",
       "9999     8  343000   8120601  27000      4096       4913          3375   \n",
       "\n",
       "      intelligence  wisdom  charisma  strength_modifier  dexterity_modifier  \\\n",
       "0              343    2197      4096                  8                   8   \n",
       "1             2197    2197      4913                  0                   0   \n",
       "2             2197    1000      5832                  8                  27   \n",
       "3             1000    2197      4096                 -1                  64   \n",
       "4             2744    1000       729                 -1                  27   \n",
       "...            ...     ...       ...                ...                 ...   \n",
       "9995          2197    3375      2197                  1                  64   \n",
       "9996           216    2744      8000                 -1                   8   \n",
       "9997          1728    1728      3375                -27                 -27   \n",
       "9998          3375     729      4096                  1                  27   \n",
       "9999          1728    2197      2197                 27                  27   \n",
       "\n",
       "      constitution_modifier  intelligence_modifier  wisdom_modifier  \\\n",
       "0                         1                     -8                1   \n",
       "1                         0                      1                1   \n",
       "2                         0                      1                0   \n",
       "3                        -8                      0                1   \n",
       "4                         8                      8                0   \n",
       "...                     ...                    ...              ...   \n",
       "9995                     27                      1                8   \n",
       "9996                      1                     -8                8   \n",
       "9997                     27                      1                1   \n",
       "9998                      1                      8               -1   \n",
       "9999                      8                      1                1   \n",
       "\n",
       "      charisma_modifier  \n",
       "0                    27  \n",
       "1                    27  \n",
       "2                    64  \n",
       "3                    27  \n",
       "4                    -1  \n",
       "...                 ...  \n",
       "9995                  1  \n",
       "9996                125  \n",
       "9997                  8  \n",
       "9998                 27  \n",
       "9999                  1  \n",
       "\n",
       "[10000 rows x 16 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_7 = df_6.copy()\n",
    "\n",
    "for i in  range(df_6.shape[1]-1):\n",
    "    df_7[df_7.columns[i+1]]=df_6[df_6.columns[i+1]]**3\n",
    "\n",
    "df_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df_7['race'] = label_encoder.fit_transform(df_7['race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_7.drop(\"race\",axis=1)\n",
    "y = df_7[\"race\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 3ms/step - loss: 1.9993 - accuracy: 0.3870 - val_loss: 2.4815 - val_accuracy: 0.1831\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1786 - accuracy: 0.5003 - val_loss: 1.0013 - val_accuracy: 0.5606\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1058 - accuracy: 0.5319 - val_loss: 0.8976 - val_accuracy: 0.6050\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0606 - accuracy: 0.5433 - val_loss: 0.8851 - val_accuracy: 0.6181\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0171 - accuracy: 0.5550 - val_loss: 0.8753 - val_accuracy: 0.6325\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0143 - accuracy: 0.5594 - val_loss: 0.8724 - val_accuracy: 0.6181\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0005 - accuracy: 0.5630 - val_loss: 0.8833 - val_accuracy: 0.6081\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9974 - accuracy: 0.5706 - val_loss: 0.8634 - val_accuracy: 0.6313\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9955 - accuracy: 0.5728 - val_loss: 0.9090 - val_accuracy: 0.5856\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9933 - accuracy: 0.5753 - val_loss: 0.8596 - val_accuracy: 0.6231\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9875 - accuracy: 0.5767 - val_loss: 0.8592 - val_accuracy: 0.6256\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9755 - accuracy: 0.5839 - val_loss: 0.9153 - val_accuracy: 0.5906\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9587 - accuracy: 0.5773 - val_loss: 0.8614 - val_accuracy: 0.6344\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9524 - accuracy: 0.5848 - val_loss: 0.8826 - val_accuracy: 0.6056\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9553 - accuracy: 0.5864 - val_loss: 0.8600 - val_accuracy: 0.6294\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9576 - accuracy: 0.5884 - val_loss: 0.8687 - val_accuracy: 0.6275\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9571 - accuracy: 0.5911 - val_loss: 0.8545 - val_accuracy: 0.6319\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9591 - accuracy: 0.5900 - val_loss: 0.8491 - val_accuracy: 0.6425\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9470 - accuracy: 0.5847 - val_loss: 0.8477 - val_accuracy: 0.6419\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9464 - accuracy: 0.5900 - val_loss: 0.8494 - val_accuracy: 0.6250\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9376 - accuracy: 0.5895 - val_loss: 0.8796 - val_accuracy: 0.6144\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9417 - accuracy: 0.5894 - val_loss: 0.8470 - val_accuracy: 0.6369\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9368 - accuracy: 0.5942 - val_loss: 0.8453 - val_accuracy: 0.6463\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9407 - accuracy: 0.5961 - val_loss: 0.8693 - val_accuracy: 0.6237\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9281 - accuracy: 0.5945 - val_loss: 0.8413 - val_accuracy: 0.6375\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9291 - accuracy: 0.6002 - val_loss: 0.9045 - val_accuracy: 0.6025\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9337 - accuracy: 0.6012 - val_loss: 0.8445 - val_accuracy: 0.6419\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9407 - accuracy: 0.5972 - val_loss: 0.8372 - val_accuracy: 0.6413\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9428 - accuracy: 0.5950 - val_loss: 0.8928 - val_accuracy: 0.6125\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9398 - accuracy: 0.5984 - val_loss: 0.8381 - val_accuracy: 0.6406\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9315 - accuracy: 0.5970 - val_loss: 0.8804 - val_accuracy: 0.6156\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9318 - accuracy: 0.5987 - val_loss: 0.8689 - val_accuracy: 0.6281\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9483 - accuracy: 0.5922 - val_loss: 0.8482 - val_accuracy: 0.6419\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9306 - accuracy: 0.5956 - val_loss: 0.8578 - val_accuracy: 0.6300\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9357 - accuracy: 0.5992 - val_loss: 0.8534 - val_accuracy: 0.6363\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9284 - accuracy: 0.6014 - val_loss: 0.8316 - val_accuracy: 0.6413\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9390 - accuracy: 0.5980 - val_loss: 0.8499 - val_accuracy: 0.6469\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9363 - accuracy: 0.6003 - val_loss: 0.8348 - val_accuracy: 0.6438\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9275 - accuracy: 0.5930 - val_loss: 0.8638 - val_accuracy: 0.6281\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9375 - accuracy: 0.5981 - val_loss: 0.8322 - val_accuracy: 0.6413\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9289 - accuracy: 0.6041 - val_loss: 0.8457 - val_accuracy: 0.6281\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9186 - accuracy: 0.6020 - val_loss: 0.8357 - val_accuracy: 0.6438\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9330 - accuracy: 0.5997 - val_loss: 0.8434 - val_accuracy: 0.6394\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9294 - accuracy: 0.5987 - val_loss: 0.8807 - val_accuracy: 0.6081\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9340 - accuracy: 0.6012 - val_loss: 0.8376 - val_accuracy: 0.6481\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9356 - accuracy: 0.6006 - val_loss: 0.8750 - val_accuracy: 0.6169\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9277 - accuracy: 0.5942 - val_loss: 0.8341 - val_accuracy: 0.6450\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9218 - accuracy: 0.6017 - val_loss: 0.8395 - val_accuracy: 0.6406\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9177 - accuracy: 0.6075 - val_loss: 0.8701 - val_accuracy: 0.6200\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9242 - accuracy: 0.6105 - val_loss: 0.8968 - val_accuracy: 0.6106\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9204 - accuracy: 0.6062 - val_loss: 0.8279 - val_accuracy: 0.6438\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9098 - accuracy: 0.6048 - val_loss: 0.8274 - val_accuracy: 0.6438\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9073 - accuracy: 0.6056 - val_loss: 0.8339 - val_accuracy: 0.6456\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9131 - accuracy: 0.6095 - val_loss: 0.8350 - val_accuracy: 0.6413\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9123 - accuracy: 0.6070 - val_loss: 0.8417 - val_accuracy: 0.6475\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9138 - accuracy: 0.6027 - val_loss: 0.8449 - val_accuracy: 0.6375\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9063 - accuracy: 0.6061 - val_loss: 0.8561 - val_accuracy: 0.6413\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9032 - accuracy: 0.6087 - val_loss: 0.8700 - val_accuracy: 0.6394\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9077 - accuracy: 0.6062 - val_loss: 0.8479 - val_accuracy: 0.6206\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9204 - accuracy: 0.6067 - val_loss: 0.8675 - val_accuracy: 0.6344\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9181 - accuracy: 0.5989 - val_loss: 0.8342 - val_accuracy: 0.6369\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9013 - accuracy: 0.6122 - val_loss: 0.8390 - val_accuracy: 0.6463\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8960 - accuracy: 0.6114 - val_loss: 0.8507 - val_accuracy: 0.6344\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9211 - accuracy: 0.6014 - val_loss: 0.8440 - val_accuracy: 0.6381\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9108 - accuracy: 0.6025 - val_loss: 0.8241 - val_accuracy: 0.6519\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9133 - accuracy: 0.6091 - val_loss: 0.8311 - val_accuracy: 0.6463\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9163 - accuracy: 0.6034 - val_loss: 0.8343 - val_accuracy: 0.6481\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9179 - accuracy: 0.6056 - val_loss: 0.8786 - val_accuracy: 0.6081\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9017 - accuracy: 0.6070 - val_loss: 0.8399 - val_accuracy: 0.6356\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8975 - accuracy: 0.6084 - val_loss: 0.8277 - val_accuracy: 0.6406\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8962 - accuracy: 0.6070 - val_loss: 0.8344 - val_accuracy: 0.6331\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9027 - accuracy: 0.6156 - val_loss: 0.8130 - val_accuracy: 0.6450\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9042 - accuracy: 0.6106 - val_loss: 0.8103 - val_accuracy: 0.6488\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8912 - accuracy: 0.6055 - val_loss: 0.8304 - val_accuracy: 0.6406\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9099 - accuracy: 0.6139 - val_loss: 0.8247 - val_accuracy: 0.6400\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9048 - accuracy: 0.6048 - val_loss: 0.8274 - val_accuracy: 0.6363\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8973 - accuracy: 0.6178 - val_loss: 0.8230 - val_accuracy: 0.6469\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9079 - accuracy: 0.6103 - val_loss: 0.8223 - val_accuracy: 0.6425\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9061 - accuracy: 0.6033 - val_loss: 0.8470 - val_accuracy: 0.6200\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9181 - accuracy: 0.6039 - val_loss: 0.8318 - val_accuracy: 0.6294\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9120 - accuracy: 0.6119 - val_loss: 0.8261 - val_accuracy: 0.6419\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8983 - accuracy: 0.6094 - val_loss: 0.8225 - val_accuracy: 0.6406\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9102 - accuracy: 0.6070 - val_loss: 0.8142 - val_accuracy: 0.6519\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9061 - accuracy: 0.6084 - val_loss: 0.8429 - val_accuracy: 0.6363\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9065 - accuracy: 0.6106 - val_loss: 0.8788 - val_accuracy: 0.6087\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9109 - accuracy: 0.6064 - val_loss: 0.8306 - val_accuracy: 0.6413\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9072 - accuracy: 0.6070 - val_loss: 0.8194 - val_accuracy: 0.6494\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8999 - accuracy: 0.6141 - val_loss: 0.8102 - val_accuracy: 0.6525\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9076 - accuracy: 0.6030 - val_loss: 0.8435 - val_accuracy: 0.6381\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9130 - accuracy: 0.6059 - val_loss: 0.8208 - val_accuracy: 0.6475\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9158 - accuracy: 0.6077 - val_loss: 0.8243 - val_accuracy: 0.6506\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9100 - accuracy: 0.6119 - val_loss: 0.8213 - val_accuracy: 0.6525\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9042 - accuracy: 0.6117 - val_loss: 0.8211 - val_accuracy: 0.6400\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9011 - accuracy: 0.6131 - val_loss: 0.8219 - val_accuracy: 0.6381\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9060 - accuracy: 0.6158 - val_loss: 0.8256 - val_accuracy: 0.6363\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9102 - accuracy: 0.6136 - val_loss: 0.8184 - val_accuracy: 0.6388\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9042 - accuracy: 0.6077 - val_loss: 0.8326 - val_accuracy: 0.6306\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9017 - accuracy: 0.6053 - val_loss: 0.8087 - val_accuracy: 0.6519\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9121 - accuracy: 0.6019 - val_loss: 0.8138 - val_accuracy: 0.6475\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9069 - accuracy: 0.6077 - val_loss: 0.8212 - val_accuracy: 0.6375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2722c2133d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 903us/step - loss: 0.9566 - accuracy: 0.6285\n",
      "Mean Squared Error on Test Set: 0.9566486477851868\n",
      "Accuracy on the test set: 0.6284999847412109\n",
      "63/63 [==============================] - 0s 758us/step\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Mean Squared Error on Test Set: {loss}')\n",
    "print(f\"Accuracy on the test set: {accuracy}\")\n",
    "\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>speed</th>\n",
       "      <th>strength</th>\n",
       "      <th>dexterity</th>\n",
       "      <th>constitution</th>\n",
       "      <th>intelligence</th>\n",
       "      <th>wisdom</th>\n",
       "      <th>charisma</th>\n",
       "      <th>strength_modifier</th>\n",
       "      <th>dexterity_modifier</th>\n",
       "      <th>constitution_modifier</th>\n",
       "      <th>intelligence_modifier</th>\n",
       "      <th>wisdom_modifier</th>\n",
       "      <th>charisma_modifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>38950081</td>\n",
       "      <td>6059221281</td>\n",
       "      <td>810000</td>\n",
       "      <td>38416</td>\n",
       "      <td>50625</td>\n",
       "      <td>20736</td>\n",
       "      <td>2401</td>\n",
       "      <td>28561</td>\n",
       "      <td>65536</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>-128</td>\n",
       "      <td>1</td>\n",
       "      <td>2187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>38950081</td>\n",
       "      <td>12003612721</td>\n",
       "      <td>810000</td>\n",
       "      <td>14641</td>\n",
       "      <td>14641</td>\n",
       "      <td>14641</td>\n",
       "      <td>28561</td>\n",
       "      <td>28561</td>\n",
       "      <td>83521</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>25411681</td>\n",
       "      <td>2798410000</td>\n",
       "      <td>810000</td>\n",
       "      <td>38416</td>\n",
       "      <td>65536</td>\n",
       "      <td>14641</td>\n",
       "      <td>28561</td>\n",
       "      <td>10000</td>\n",
       "      <td>104976</td>\n",
       "      <td>128</td>\n",
       "      <td>2187</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>31640625</td>\n",
       "      <td>4931550625</td>\n",
       "      <td>810000</td>\n",
       "      <td>4096</td>\n",
       "      <td>130321</td>\n",
       "      <td>2401</td>\n",
       "      <td>10000</td>\n",
       "      <td>28561</td>\n",
       "      <td>65536</td>\n",
       "      <td>-1</td>\n",
       "      <td>16384</td>\n",
       "      <td>-128</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>26873856</td>\n",
       "      <td>2750058481</td>\n",
       "      <td>810000</td>\n",
       "      <td>4096</td>\n",
       "      <td>83521</td>\n",
       "      <td>38416</td>\n",
       "      <td>38416</td>\n",
       "      <td>10000</td>\n",
       "      <td>6561</td>\n",
       "      <td>-1</td>\n",
       "      <td>2187</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>8</td>\n",
       "      <td>15752961</td>\n",
       "      <td>454371856</td>\n",
       "      <td>810000</td>\n",
       "      <td>28561</td>\n",
       "      <td>104976</td>\n",
       "      <td>83521</td>\n",
       "      <td>28561</td>\n",
       "      <td>50625</td>\n",
       "      <td>28561</td>\n",
       "      <td>1</td>\n",
       "      <td>16384</td>\n",
       "      <td>2187</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>8</td>\n",
       "      <td>26873856</td>\n",
       "      <td>2798410000</td>\n",
       "      <td>810000</td>\n",
       "      <td>4096</td>\n",
       "      <td>38416</td>\n",
       "      <td>28561</td>\n",
       "      <td>1296</td>\n",
       "      <td>38416</td>\n",
       "      <td>160000</td>\n",
       "      <td>-1</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>-128</td>\n",
       "      <td>128</td>\n",
       "      <td>78125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>8</td>\n",
       "      <td>18974736</td>\n",
       "      <td>352275361</td>\n",
       "      <td>810000</td>\n",
       "      <td>256</td>\n",
       "      <td>625</td>\n",
       "      <td>65536</td>\n",
       "      <td>20736</td>\n",
       "      <td>20736</td>\n",
       "      <td>50625</td>\n",
       "      <td>-2187</td>\n",
       "      <td>-2187</td>\n",
       "      <td>2187</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>8</td>\n",
       "      <td>21381376</td>\n",
       "      <td>418161601</td>\n",
       "      <td>810000</td>\n",
       "      <td>20736</td>\n",
       "      <td>65536</td>\n",
       "      <td>20736</td>\n",
       "      <td>50625</td>\n",
       "      <td>6561</td>\n",
       "      <td>65536</td>\n",
       "      <td>1</td>\n",
       "      <td>2187</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>-1</td>\n",
       "      <td>2187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>8</td>\n",
       "      <td>24010000</td>\n",
       "      <td>1632240801</td>\n",
       "      <td>810000</td>\n",
       "      <td>65536</td>\n",
       "      <td>83521</td>\n",
       "      <td>50625</td>\n",
       "      <td>20736</td>\n",
       "      <td>28561</td>\n",
       "      <td>28561</td>\n",
       "      <td>2187</td>\n",
       "      <td>2187</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      race    height       weight   speed  strength  dexterity  constitution  \\\n",
       "0        0  38950081   6059221281  810000     38416      50625         20736   \n",
       "1        0  38950081  12003612721  810000     14641      14641         14641   \n",
       "2        0  25411681   2798410000  810000     38416      65536         14641   \n",
       "3        0  31640625   4931550625  810000      4096     130321          2401   \n",
       "4        0  26873856   2750058481  810000      4096      83521         38416   \n",
       "...    ...       ...          ...     ...       ...        ...           ...   \n",
       "9995     8  15752961    454371856  810000     28561     104976         83521   \n",
       "9996     8  26873856   2798410000  810000      4096      38416         28561   \n",
       "9997     8  18974736    352275361  810000       256        625         65536   \n",
       "9998     8  21381376    418161601  810000     20736      65536         20736   \n",
       "9999     8  24010000   1632240801  810000     65536      83521         50625   \n",
       "\n",
       "      intelligence  wisdom  charisma  strength_modifier  dexterity_modifier  \\\n",
       "0             2401   28561     65536                128                 128   \n",
       "1            28561   28561     83521                  0                   0   \n",
       "2            28561   10000    104976                128                2187   \n",
       "3            10000   28561     65536                 -1               16384   \n",
       "4            38416   10000      6561                 -1                2187   \n",
       "...            ...     ...       ...                ...                 ...   \n",
       "9995         28561   50625     28561                  1               16384   \n",
       "9996          1296   38416    160000                 -1                 128   \n",
       "9997         20736   20736     50625              -2187               -2187   \n",
       "9998         50625    6561     65536                  1                2187   \n",
       "9999         20736   28561     28561               2187                2187   \n",
       "\n",
       "      constitution_modifier  intelligence_modifier  wisdom_modifier  \\\n",
       "0                         1                   -128                1   \n",
       "1                         0                      1                1   \n",
       "2                         0                      1                0   \n",
       "3                      -128                      0                1   \n",
       "4                       128                    128                0   \n",
       "...                     ...                    ...              ...   \n",
       "9995                   2187                      1              128   \n",
       "9996                      1                   -128              128   \n",
       "9997                   2187                      1                1   \n",
       "9998                      1                    128               -1   \n",
       "9999                    128                      1                1   \n",
       "\n",
       "      charisma_modifier  \n",
       "0                  2187  \n",
       "1                  2187  \n",
       "2                 16384  \n",
       "3                  2187  \n",
       "4                    -1  \n",
       "...                 ...  \n",
       "9995                  1  \n",
       "9996              78125  \n",
       "9997                128  \n",
       "9998               2187  \n",
       "9999                  1  \n",
       "\n",
       "[10000 rows x 16 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_9 = df_6.copy()\n",
    "\n",
    "for i in  range(df_6.shape[1]-6):\n",
    "   df_9[df_9.columns[i+1]]=df_6[df_6.columns[i+1]]**4\n",
    "for i in  range(df_6.shape[1]-10):\n",
    "    df_9[df_9.columns[i+10]]=df_6[df_6.columns[i+10]]**7\n",
    "\n",
    "df_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df_9['race'] = label_encoder.fit_transform(df_9['race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_9.drop(\"race\",axis=1)\n",
    "y = df_9[\"race\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 2s 3ms/step - loss: 0.9816 - accuracy: 0.5848 - val_loss: 1.6752 - val_accuracy: 0.4631\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9359 - accuracy: 0.5972 - val_loss: 0.9893 - val_accuracy: 0.5838\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9410 - accuracy: 0.5936 - val_loss: 0.9879 - val_accuracy: 0.5825\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9428 - accuracy: 0.6053 - val_loss: 0.8283 - val_accuracy: 0.6394\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9495 - accuracy: 0.5959 - val_loss: 0.8223 - val_accuracy: 0.6450\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9333 - accuracy: 0.5984 - val_loss: 0.8169 - val_accuracy: 0.6313\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9211 - accuracy: 0.5991 - val_loss: 0.8405 - val_accuracy: 0.6237\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9252 - accuracy: 0.6083 - val_loss: 0.8380 - val_accuracy: 0.6094\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9321 - accuracy: 0.6023 - val_loss: 0.8318 - val_accuracy: 0.6263\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9483 - accuracy: 0.5959 - val_loss: 0.8096 - val_accuracy: 0.6388\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9170 - accuracy: 0.5997 - val_loss: 0.8188 - val_accuracy: 0.6406\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9236 - accuracy: 0.6030 - val_loss: 0.8632 - val_accuracy: 0.6112\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9330 - accuracy: 0.5970 - val_loss: 0.8328 - val_accuracy: 0.6331\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9288 - accuracy: 0.5964 - val_loss: 0.8091 - val_accuracy: 0.6419\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9359 - accuracy: 0.5906 - val_loss: 0.8606 - val_accuracy: 0.6263\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9255 - accuracy: 0.5953 - val_loss: 0.8213 - val_accuracy: 0.6394\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9111 - accuracy: 0.5964 - val_loss: 6.5179 - val_accuracy: 0.3519\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9263 - accuracy: 0.6037 - val_loss: 0.8217 - val_accuracy: 0.6306\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9189 - accuracy: 0.6100 - val_loss: 0.8131 - val_accuracy: 0.6256\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9334 - accuracy: 0.6012 - val_loss: 0.8367 - val_accuracy: 0.6244\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9213 - accuracy: 0.5995 - val_loss: 0.9091 - val_accuracy: 0.6069\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9249 - accuracy: 0.6027 - val_loss: 0.8154 - val_accuracy: 0.6469\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9195 - accuracy: 0.6023 - val_loss: 0.8146 - val_accuracy: 0.6425\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9233 - accuracy: 0.6033 - val_loss: 0.8094 - val_accuracy: 0.6444\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9211 - accuracy: 0.6062 - val_loss: 0.8292 - val_accuracy: 0.6225\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9190 - accuracy: 0.5995 - val_loss: 0.8078 - val_accuracy: 0.6506\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9107 - accuracy: 0.6031 - val_loss: 0.8078 - val_accuracy: 0.6388\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9160 - accuracy: 0.5975 - val_loss: 0.8302 - val_accuracy: 0.6450\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9290 - accuracy: 0.6006 - val_loss: 0.8380 - val_accuracy: 0.6237\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9221 - accuracy: 0.6064 - val_loss: 0.8299 - val_accuracy: 0.6338\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9133 - accuracy: 0.5986 - val_loss: 0.8356 - val_accuracy: 0.6256\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9225 - accuracy: 0.5983 - val_loss: 0.8712 - val_accuracy: 0.6219\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9156 - accuracy: 0.5972 - val_loss: 0.8084 - val_accuracy: 0.6331\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9046 - accuracy: 0.6112 - val_loss: 0.8070 - val_accuracy: 0.6381\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9254 - accuracy: 0.5948 - val_loss: 0.8093 - val_accuracy: 0.6494\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9159 - accuracy: 0.6011 - val_loss: 0.8291 - val_accuracy: 0.6231\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9165 - accuracy: 0.6102 - val_loss: 0.8818 - val_accuracy: 0.6000\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9193 - accuracy: 0.6003 - val_loss: 0.8420 - val_accuracy: 0.6194\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9121 - accuracy: 0.6044 - val_loss: 0.8229 - val_accuracy: 0.6363\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9118 - accuracy: 0.6016 - val_loss: 0.8604 - val_accuracy: 0.6125\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9245 - accuracy: 0.6030 - val_loss: 0.8065 - val_accuracy: 0.6456\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9171 - accuracy: 0.6037 - val_loss: 0.8363 - val_accuracy: 0.6237\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9125 - accuracy: 0.6077 - val_loss: 0.8214 - val_accuracy: 0.6369\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9173 - accuracy: 0.5978 - val_loss: 0.8551 - val_accuracy: 0.6100\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9206 - accuracy: 0.5958 - val_loss: 0.8462 - val_accuracy: 0.6175\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9081 - accuracy: 0.5991 - val_loss: 0.8114 - val_accuracy: 0.6431\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9056 - accuracy: 0.6105 - val_loss: 0.8403 - val_accuracy: 0.6219\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9124 - accuracy: 0.5986 - val_loss: 0.8120 - val_accuracy: 0.6388\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9215 - accuracy: 0.6023 - val_loss: 0.8555 - val_accuracy: 0.5994\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9138 - accuracy: 0.6034 - val_loss: 0.8196 - val_accuracy: 0.6325\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9055 - accuracy: 0.6084 - val_loss: 0.8448 - val_accuracy: 0.6112\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9071 - accuracy: 0.6039 - val_loss: 0.8076 - val_accuracy: 0.6356\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9167 - accuracy: 0.6037 - val_loss: 0.8242 - val_accuracy: 0.6325\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9109 - accuracy: 0.6066 - val_loss: 0.8417 - val_accuracy: 0.6119\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9067 - accuracy: 0.6017 - val_loss: 0.7994 - val_accuracy: 0.6494\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9080 - accuracy: 0.6039 - val_loss: 0.8025 - val_accuracy: 0.6450\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9007 - accuracy: 0.6011 - val_loss: 0.8022 - val_accuracy: 0.6475\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9097 - accuracy: 0.5986 - val_loss: 0.8275 - val_accuracy: 0.6269\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8966 - accuracy: 0.6058 - val_loss: 0.8617 - val_accuracy: 0.6162\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9158 - accuracy: 0.6036 - val_loss: 0.8043 - val_accuracy: 0.6500\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9190 - accuracy: 0.6006 - val_loss: 0.8126 - val_accuracy: 0.6400\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9172 - accuracy: 0.6028 - val_loss: 0.7979 - val_accuracy: 0.6481\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9183 - accuracy: 0.6050 - val_loss: 0.8425 - val_accuracy: 0.6175\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9271 - accuracy: 0.5927 - val_loss: 0.8134 - val_accuracy: 0.6406\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9233 - accuracy: 0.5947 - val_loss: 0.8389 - val_accuracy: 0.6319\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9095 - accuracy: 0.6056 - val_loss: 0.8218 - val_accuracy: 0.6538\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9141 - accuracy: 0.5997 - val_loss: 0.8220 - val_accuracy: 0.6381\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9026 - accuracy: 0.6064 - val_loss: 0.7976 - val_accuracy: 0.6469\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8936 - accuracy: 0.6116 - val_loss: 0.7969 - val_accuracy: 0.6450\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9029 - accuracy: 0.6028 - val_loss: 0.8062 - val_accuracy: 0.6463\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9194 - accuracy: 0.6048 - val_loss: 0.8136 - val_accuracy: 0.6350\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9047 - accuracy: 0.6002 - val_loss: 0.8067 - val_accuracy: 0.6338\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9093 - accuracy: 0.5987 - val_loss: 0.8210 - val_accuracy: 0.6363\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9069 - accuracy: 0.6061 - val_loss: 0.8027 - val_accuracy: 0.6400\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9198 - accuracy: 0.5961 - val_loss: 0.8206 - val_accuracy: 0.6406\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9235 - accuracy: 0.6022 - val_loss: 0.8406 - val_accuracy: 0.6294\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9140 - accuracy: 0.6002 - val_loss: 0.8180 - val_accuracy: 0.6469\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9031 - accuracy: 0.6025 - val_loss: 0.8868 - val_accuracy: 0.6075\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9246 - accuracy: 0.6055 - val_loss: 0.8196 - val_accuracy: 0.6350\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9220 - accuracy: 0.6017 - val_loss: 0.8065 - val_accuracy: 0.6469\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9090 - accuracy: 0.6061 - val_loss: 8.4304 - val_accuracy: 0.3925\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9285 - accuracy: 0.5975 - val_loss: 0.8327 - val_accuracy: 0.6231\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9055 - accuracy: 0.6077 - val_loss: 0.8041 - val_accuracy: 0.6475\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9085 - accuracy: 0.6028 - val_loss: 0.8450 - val_accuracy: 0.6263\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9135 - accuracy: 0.6058 - val_loss: 0.8065 - val_accuracy: 0.6469\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9120 - accuracy: 0.6062 - val_loss: 0.8045 - val_accuracy: 0.6481\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9002 - accuracy: 0.6117 - val_loss: 0.8147 - val_accuracy: 0.6356\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9253 - accuracy: 0.6008 - val_loss: 0.8015 - val_accuracy: 0.6381\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9103 - accuracy: 0.6075 - val_loss: 0.8219 - val_accuracy: 0.6288\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9008 - accuracy: 0.6095 - val_loss: 0.8401 - val_accuracy: 0.6187\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8982 - accuracy: 0.6081 - val_loss: 0.8213 - val_accuracy: 0.6413\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8988 - accuracy: 0.6037 - val_loss: 0.8084 - val_accuracy: 0.6363\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9100 - accuracy: 0.6087 - val_loss: 0.8036 - val_accuracy: 0.6469\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9123 - accuracy: 0.6028 - val_loss: 0.8032 - val_accuracy: 0.6381\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9112 - accuracy: 0.6092 - val_loss: 0.8102 - val_accuracy: 0.6450\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8979 - accuracy: 0.6105 - val_loss: 0.8013 - val_accuracy: 0.6438\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9068 - accuracy: 0.6086 - val_loss: 0.7955 - val_accuracy: 0.6488\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9098 - accuracy: 0.6062 - val_loss: 0.8048 - val_accuracy: 0.6350\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9038 - accuracy: 0.6094 - val_loss: 0.8021 - val_accuracy: 0.6394\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9074 - accuracy: 0.6058 - val_loss: 0.8192 - val_accuracy: 0.6313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x27234bc7bd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 936us/step - loss: 0.8432 - accuracy: 0.6055\n",
      "Mean Squared Error on Test Set: 0.8431699872016907\n",
      "Accuracy on the test set: 0.6054999828338623\n",
      "63/63 [==============================] - 0s 855us/step\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Mean Squared Error on Test Set: {loss}')\n",
    "print(f\"Accuracy on the test set: {accuracy}\")\n",
    "\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "decision_tree_model = DecisionTreeClassifier(criterion=\"gini\",max_depth=10)\n",
    "decision_tree_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_tree_predictions = decision_tree_model.predict(X_train)\n",
    "test_tree_predictions = decision_tree_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train_combined = np.column_stack((X_train, train_tree_predictions))\n",
    "X_test_combined = np.column_stack((X_test, test_tree_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "num_classes = len(np.unique(y))\n",
    "y_train_onehot = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_onehot = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/125 [==============================] - 2s 3ms/step - loss: 2.3249 - accuracy: 0.2286 - val_loss: 1.4594 - val_accuracy: 0.4725\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.7392 - accuracy: 0.3414 - val_loss: 1.3078 - val_accuracy: 0.4595\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.5337 - accuracy: 0.3930 - val_loss: 1.2845 - val_accuracy: 0.4390\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.3922 - accuracy: 0.4445 - val_loss: 1.2158 - val_accuracy: 0.5335\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.2695 - accuracy: 0.4846 - val_loss: 1.1568 - val_accuracy: 0.5245\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.1730 - accuracy: 0.5107 - val_loss: 1.2930 - val_accuracy: 0.4635\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.1284 - accuracy: 0.5291 - val_loss: 1.0205 - val_accuracy: 0.5790\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.1079 - accuracy: 0.5276 - val_loss: 0.9788 - val_accuracy: 0.5615\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0729 - accuracy: 0.5379 - val_loss: 0.9566 - val_accuracy: 0.5745\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0677 - accuracy: 0.5405 - val_loss: 0.9328 - val_accuracy: 0.5910\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0542 - accuracy: 0.5434 - val_loss: 1.2178 - val_accuracy: 0.4965\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0541 - accuracy: 0.5479 - val_loss: 0.9294 - val_accuracy: 0.5940\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0477 - accuracy: 0.5491 - val_loss: 0.9347 - val_accuracy: 0.5800\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0456 - accuracy: 0.5428 - val_loss: 0.9454 - val_accuracy: 0.5755\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0169 - accuracy: 0.5509 - val_loss: 0.9315 - val_accuracy: 0.5870\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0209 - accuracy: 0.5502 - val_loss: 0.9166 - val_accuracy: 0.6020\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0068 - accuracy: 0.5511 - val_loss: 0.9160 - val_accuracy: 0.5950\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0379 - accuracy: 0.5555 - val_loss: 0.9192 - val_accuracy: 0.5890\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0078 - accuracy: 0.5640 - val_loss: 0.9079 - val_accuracy: 0.5990\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9999 - accuracy: 0.5592 - val_loss: 0.9089 - val_accuracy: 0.5990\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0009 - accuracy: 0.5644 - val_loss: 0.9047 - val_accuracy: 0.6020\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9929 - accuracy: 0.5611 - val_loss: 0.9160 - val_accuracy: 0.5945\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0037 - accuracy: 0.5630 - val_loss: 0.9130 - val_accuracy: 0.5945\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9911 - accuracy: 0.5646 - val_loss: 0.9316 - val_accuracy: 0.5860\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9887 - accuracy: 0.5596 - val_loss: 0.9047 - val_accuracy: 0.6075\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9934 - accuracy: 0.5634 - val_loss: 0.9104 - val_accuracy: 0.5925\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9954 - accuracy: 0.5650 - val_loss: 0.9081 - val_accuracy: 0.5940\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9802 - accuracy: 0.5698 - val_loss: 0.9052 - val_accuracy: 0.6030\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9711 - accuracy: 0.5746 - val_loss: 0.9054 - val_accuracy: 0.5935\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9706 - accuracy: 0.5749 - val_loss: 0.8848 - val_accuracy: 0.6140\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9876 - accuracy: 0.5698 - val_loss: 0.8906 - val_accuracy: 0.6110\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9788 - accuracy: 0.5695 - val_loss: 0.8873 - val_accuracy: 0.6120\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9660 - accuracy: 0.5821 - val_loss: 0.8820 - val_accuracy: 0.6110\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9704 - accuracy: 0.5715 - val_loss: 0.8839 - val_accuracy: 0.6095\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9896 - accuracy: 0.5711 - val_loss: 0.8813 - val_accuracy: 0.6130\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9778 - accuracy: 0.5686 - val_loss: 0.9040 - val_accuracy: 0.5980\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9705 - accuracy: 0.5753 - val_loss: 0.9213 - val_accuracy: 0.5975\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9731 - accuracy: 0.5744 - val_loss: 0.9080 - val_accuracy: 0.5930\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9759 - accuracy: 0.5740 - val_loss: 0.8974 - val_accuracy: 0.5945\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9693 - accuracy: 0.5811 - val_loss: 0.9499 - val_accuracy: 0.5745\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9817 - accuracy: 0.5674 - val_loss: 0.8854 - val_accuracy: 0.6080\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9613 - accuracy: 0.5842 - val_loss: 0.8853 - val_accuracy: 0.6040\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9861 - accuracy: 0.5825 - val_loss: 0.9090 - val_accuracy: 0.5870\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9641 - accuracy: 0.5794 - val_loss: 0.8833 - val_accuracy: 0.5985\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9596 - accuracy: 0.5761 - val_loss: 0.9463 - val_accuracy: 0.5675\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9720 - accuracy: 0.5707 - val_loss: 0.8823 - val_accuracy: 0.6030\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9778 - accuracy: 0.5779 - val_loss: 0.8778 - val_accuracy: 0.6060\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9756 - accuracy: 0.5740 - val_loss: 0.8707 - val_accuracy: 0.6120\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9561 - accuracy: 0.5803 - val_loss: 0.8725 - val_accuracy: 0.6065\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9543 - accuracy: 0.5851 - val_loss: 0.8882 - val_accuracy: 0.6030\n",
      "63/63 [==============================] - 0s 855us/step - loss: 0.8882 - accuracy: 0.6030\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "        tf.keras.layers.Dense(256, input_dim=X_train.shape[1]+1, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "    tf.keras.layers.Dense(len(df['race'].unique()), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_combined, y_train_onehot, epochs=50, batch_size=64, validation_data=(X_test_combined, y_test_onehot))\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test_combined, y_test_onehot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6029999852180481\n"
     ]
    }
   ],
   "source": [
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(algorithm=&#x27;kd_tree&#x27;, metric=&#x27;euclidean&#x27;, n_neighbors=7,\n",
       "                     weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(algorithm=&#x27;kd_tree&#x27;, metric=&#x27;euclidean&#x27;, n_neighbors=7,\n",
       "                     weights=&#x27;distance&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(algorithm='kd_tree', metric='euclidean', n_neighbors=7,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=7,weights=\"distance\",algorithm=\"kd_tree\",p=2,leaf_size=30,metric=\"euclidean\")\n",
    "knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_knn_predictions = knn_model.predict(X_train)\n",
    "test_knn_predictions = knn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_combined = np.column_stack((X_train, train_knn_predictions))\n",
    "X_test_combined = np.column_stack((X_test, test_knn_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/125 [==============================] - 2s 4ms/step - loss: 2.1127 - accuracy: 0.3029 - val_loss: 1.3254 - val_accuracy: 0.4325\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4981 - accuracy: 0.4392 - val_loss: 1.2168 - val_accuracy: 0.4975\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.3116 - accuracy: 0.4939 - val_loss: 1.1290 - val_accuracy: 0.5345\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.2027 - accuracy: 0.5126 - val_loss: 1.2607 - val_accuracy: 0.4395\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.1211 - accuracy: 0.5305 - val_loss: 1.1291 - val_accuracy: 0.5075\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.0806 - accuracy: 0.5422 - val_loss: 1.0126 - val_accuracy: 0.5490\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.0603 - accuracy: 0.5504 - val_loss: 0.9821 - val_accuracy: 0.5595\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.0345 - accuracy: 0.5576 - val_loss: 1.1061 - val_accuracy: 0.5280\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.0283 - accuracy: 0.5589 - val_loss: 1.0242 - val_accuracy: 0.5435\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.0162 - accuracy: 0.5554 - val_loss: 0.9230 - val_accuracy: 0.5770\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9989 - accuracy: 0.5734 - val_loss: 0.9520 - val_accuracy: 0.5730\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9946 - accuracy: 0.5644 - val_loss: 0.9306 - val_accuracy: 0.5760\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9918 - accuracy: 0.5660 - val_loss: 0.9119 - val_accuracy: 0.5950\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.0053 - accuracy: 0.5681 - val_loss: 0.9399 - val_accuracy: 0.5695\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9870 - accuracy: 0.5757 - val_loss: 0.9987 - val_accuracy: 0.5620\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9787 - accuracy: 0.5748 - val_loss: 0.9551 - val_accuracy: 0.5690\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9676 - accuracy: 0.5809 - val_loss: 0.9013 - val_accuracy: 0.5875\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9839 - accuracy: 0.5763 - val_loss: 0.9454 - val_accuracy: 0.5810\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9739 - accuracy: 0.5745 - val_loss: 0.9895 - val_accuracy: 0.5475\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9713 - accuracy: 0.5830 - val_loss: 0.9202 - val_accuracy: 0.5845\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9583 - accuracy: 0.5781 - val_loss: 0.8943 - val_accuracy: 0.5910\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9684 - accuracy: 0.5798 - val_loss: 0.8885 - val_accuracy: 0.5910\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9850 - accuracy: 0.5735 - val_loss: 0.9012 - val_accuracy: 0.5835\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9548 - accuracy: 0.5846 - val_loss: 0.9115 - val_accuracy: 0.5770\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9506 - accuracy: 0.5853 - val_loss: 0.8866 - val_accuracy: 0.5980\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9610 - accuracy: 0.5831 - val_loss: 0.8781 - val_accuracy: 0.6030\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9441 - accuracy: 0.5900 - val_loss: 0.9087 - val_accuracy: 0.5805\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9548 - accuracy: 0.5867 - val_loss: 0.8873 - val_accuracy: 0.6010\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9480 - accuracy: 0.5854 - val_loss: 0.9351 - val_accuracy: 0.5735\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9639 - accuracy: 0.5784 - val_loss: 0.8693 - val_accuracy: 0.6025\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9495 - accuracy: 0.5869 - val_loss: 0.8791 - val_accuracy: 0.5955\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9537 - accuracy: 0.5832 - val_loss: 0.9157 - val_accuracy: 0.5800\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9732 - accuracy: 0.5805 - val_loss: 0.9032 - val_accuracy: 0.5850\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9586 - accuracy: 0.5830 - val_loss: 0.8816 - val_accuracy: 0.6065\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9412 - accuracy: 0.5915 - val_loss: 1.0633 - val_accuracy: 0.6010\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9434 - accuracy: 0.5864 - val_loss: 1.4891 - val_accuracy: 0.5855\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9462 - accuracy: 0.5926 - val_loss: 1.5900 - val_accuracy: 0.6115\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9322 - accuracy: 0.5861 - val_loss: 1.7602 - val_accuracy: 0.5995\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9351 - accuracy: 0.5911 - val_loss: 1.8151 - val_accuracy: 0.6295\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9314 - accuracy: 0.5943 - val_loss: 1.3765 - val_accuracy: 0.5790\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9369 - accuracy: 0.5865 - val_loss: 1.7052 - val_accuracy: 0.6220\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9336 - accuracy: 0.5920 - val_loss: 1.8761 - val_accuracy: 0.6090\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9307 - accuracy: 0.5943 - val_loss: 1.4558 - val_accuracy: 0.6195\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9390 - accuracy: 0.5889 - val_loss: 1.6186 - val_accuracy: 0.6150\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9391 - accuracy: 0.5880 - val_loss: 1.9047 - val_accuracy: 0.6190\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9305 - accuracy: 0.5957 - val_loss: 1.6600 - val_accuracy: 0.6095\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9359 - accuracy: 0.5956 - val_loss: 1.2437 - val_accuracy: 0.6120\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9325 - accuracy: 0.5934 - val_loss: 1.2278 - val_accuracy: 0.6125\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9232 - accuracy: 0.5905 - val_loss: 1.0067 - val_accuracy: 0.6150\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.9371 - accuracy: 0.5962 - val_loss: 0.8851 - val_accuracy: 0.5970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x272397f1750>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "        tf.keras.layers.Dense(256, input_dim=X_train.shape[1]+1, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "    tf.keras.layers.Dense(len(df['race'].unique()), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_combined, y_train_onehot, epochs=50, batch_size=64, validation_data=(X_test_combined, y_test_onehot))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/63 [..............................] - ETA: 1s - loss: 1.2327 - accuracy: 0.4688"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.8851 - accuracy: 0.5970\n",
      "Test Accuracy: 0.597000002861023\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test_combined, y_test_onehot)\n",
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
